[
    {
        "label": "Blueprint",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "Figure",
        "importPath": "matplotlib.figure",
        "description": "matplotlib.figure",
        "isExtraImport": true,
        "detail": "matplotlib.figure",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "Tokenizer",
        "importPath": "keras.preprocessing.text",
        "description": "keras.preprocessing.text",
        "isExtraImport": true,
        "detail": "keras.preprocessing.text",
        "documentation": {}
    },
    {
        "label": "pad_sequences",
        "importPath": "keras_preprocessing.sequence",
        "description": "keras_preprocessing.sequence",
        "isExtraImport": true,
        "detail": "keras_preprocessing.sequence",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Embedding",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "SpatialDropout1D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "LabelEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "to_categorical",
        "importPath": "keras.utils",
        "description": "keras.utils",
        "isExtraImport": true,
        "detail": "keras.utils",
        "documentation": {}
    },
    {
        "label": "stopwords",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "Rake",
        "importPath": "rake_nltk",
        "description": "rake_nltk",
        "isExtraImport": true,
        "detail": "rake_nltk",
        "documentation": {}
    },
    {
        "label": "search_products",
        "kind": 2,
        "importPath": "backend.api.product_routes",
        "description": "backend.api.product_routes",
        "peekOfCode": "def search_products():\n    query = request.args.get('query', '').lower()\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    return jsonify(filtered_products)\n# API pour obtenir les d√©tails d'un produit\n@product_routes.route('/api/product_details', methods=['GET'])\ndef product_details():\n    product_url = request.args.get('product_url', '').lower()\n    product = next((product for product in product_data if product['product_link'].lower() == product_url), None)\n    if product is None:",
        "detail": "backend.api.product_routes",
        "documentation": {}
    },
    {
        "label": "product_details",
        "kind": 2,
        "importPath": "backend.api.product_routes",
        "description": "backend.api.product_routes",
        "peekOfCode": "def product_details():\n    product_url = request.args.get('product_url', '').lower()\n    product = next((product for product in product_data if product['product_link'].lower() == product_url), None)\n    if product is None:\n        return jsonify({\"error\": \"Product not found\"}), 404\n    return jsonify(product)",
        "detail": "backend.api.product_routes",
        "documentation": {}
    },
    {
        "label": "product_routes",
        "kind": 5,
        "importPath": "backend.api.product_routes",
        "description": "backend.api.product_routes",
        "peekOfCode": "product_routes = Blueprint('product_routes', __name__)\n# Charger les donn√©es produits (si n√©cessaire, mais tu peux les passer depuis app.py)\nwith open('merged_product_reviews.json', 'r', encoding='utf-8') as f:\n    product_data = json.load(f)\n# API pour rechercher des produits\n@product_routes.route('/api/search_products', methods=['GET'])\ndef search_products():\n    query = request.args.get('query', '').lower()\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    return jsonify(filtered_products)",
        "detail": "backend.api.product_routes",
        "documentation": {}
    },
    {
        "label": "home",
        "kind": 2,
        "importPath": "backend.app-beta",
        "description": "backend.app-beta",
        "peekOfCode": "def home():\n    return \"<h1>Welcome to the Sublimpick API</h1><p>Use /search_products or /product_details to interact with the API.</p>\"\n# Route to search for products by name or URL (Page 1)\n@app.route('/search_products', methods=['GET'])\ndef search_products():\n    query = request.args.get('query', '').lower()\n    # Search products by product name or part of the name\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    # Return product names and URLs\n    product_list = [{'product_name': product['product_name'], 'product_link': product['product_link']} for product in filtered_products]",
        "detail": "backend.app-beta",
        "documentation": {}
    },
    {
        "label": "search_products",
        "kind": 2,
        "importPath": "backend.app-beta",
        "description": "backend.app-beta",
        "peekOfCode": "def search_products():\n    query = request.args.get('query', '').lower()\n    # Search products by product name or part of the name\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    # Return product names and URLs\n    product_list = [{'product_name': product['product_name'], 'product_link': product['product_link']} for product in filtered_products]\n    return jsonify(product_list)\n# Route to get product details and reviews (Page 2)\n@app.route('/product_details', methods=['GET'])\ndef product_details():",
        "detail": "backend.app-beta",
        "documentation": {}
    },
    {
        "label": "product_details",
        "kind": 2,
        "importPath": "backend.app-beta",
        "description": "backend.app-beta",
        "peekOfCode": "def product_details():\n    # product_url = request.args.get('product_url', '').lower()\n    # # Find the product based on the product URL\n    # product = next((product for product in product_data if product['product_link'].lower() == product_url), None)\n    # Get the product_url from the request and normalize it\n    product_url = request.args.get('product_url', '').strip().lower().rstrip('/')\n    # Iterate over the product_data to find the matching product\n    product = next((product for product in product_data if product['product_link'].strip().lower().rstrip('/') == product_url), None)\n    if product is None:\n        return jsonify({\"error\": \"Product not found\"}), 404",
        "detail": "backend.app-beta",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app-beta",
        "description": "backend.app-beta",
        "peekOfCode": "app = Flask(__name__)\n# CORS(app)  # Enable CORS for all routes\n# Step 1: Load the JSON data (merged_product_reviews.json)\njson_file_path = 'merged_product_reviews.json'\nif os.path.exists(json_file_path):\n    with open(json_file_path, 'r', encoding='utf-8') as f:\n        product_data = json.load(f)\nelse:\n    raise FileNotFoundError(f\"{json_file_path} not found. Ensure the file exists.\")\n# Home route to avoid 404 on the root URL",
        "detail": "backend.app-beta",
        "documentation": {}
    },
    {
        "label": "json_file_path",
        "kind": 5,
        "importPath": "backend.app-beta",
        "description": "backend.app-beta",
        "peekOfCode": "json_file_path = 'merged_product_reviews.json'\nif os.path.exists(json_file_path):\n    with open(json_file_path, 'r', encoding='utf-8') as f:\n        product_data = json.load(f)\nelse:\n    raise FileNotFoundError(f\"{json_file_path} not found. Ensure the file exists.\")\n# Home route to avoid 404 on the root URL\n@app.route('/')\ndef home():\n    return \"<h1>Welcome to the Sublimpick API</h1><p>Use /search_products or /product_details to interact with the API.</p>\"",
        "detail": "backend.app-beta",
        "documentation": {}
    },
    {
        "label": "create_review_graphs",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def create_review_graphs(product_reviews):\n    df = pd.DataFrame(product_reviews)\n    df['review_collected_date'] = pd.to_datetime(df['review_collected_date'], errors='coerce')\n    df_sorted = df.sort_values(by='review_collected_date', ascending=False)\n    star_counts = df_sorted['review_stars'].value_counts().sort_index()\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.pie(star_counts, labels=star_counts.index, autopct='%1.1f%%', startangle=90)\n    ax.set_title('Distribution of Star Ratings')\n    img = BytesIO()\n    plt.savefig(img, format='png')",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "create_sentiment_graph",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def create_sentiment_graph(product_reviews):\n    df = pd.DataFrame(product_reviews)\n    sentiment_counts = df['sentiment_category'].value_counts()\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'red', 'orange'])\n    ax.set_title('Sentiment Analysis of Reviews')\n    img = BytesIO()\n    plt.savefig(img, format='png')\n    img.seek(0)\n    plot_url2 = base64.b64encode(img.getvalue()).decode()",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "create_review_trend_graph",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def create_review_trend_graph(product_reviews):\n    df = pd.DataFrame(product_reviews)\n    df['review_date'] = pd.to_datetime(df['review_date'], format='%m/%d/%y', errors='coerce')\n    fig, ax = plt.subplots(figsize=(5, 5))\n    df.set_index('review_date').resample('M').size().plot(ax=ax)\n    ax.set_title('Trend of Reviews Over Time')\n    ax.set_xlabel('Month')\n    ax.set_ylabel('Number of Reviews')\n    img = BytesIO()\n    plt.savefig(img, format='png')",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "create_keyword_graph",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def create_keyword_graph(product_reviews):\n    keywords = []\n    for review in product_reviews:\n        keywords.extend(eval(review['keywords']))\n    keyword_counts = Counter(keywords).most_common(10)\n    keywords, counts = zip(*keyword_counts)\n    fig, ax = plt.subplots(figsize=(5, 5))\n    sns.barplot(x=counts, y=keywords, ax=ax, palette=\"viridis\", legend=False, hue = keywords)\n    ax.set_title('Top 10 Keywords in Reviews')\n    img = BytesIO()",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def index():\n    return render_template('home.html')\n# Route to the search page\n@app.route('/search')\ndef search_page():\n    return render_template('index.html')\n# Route to search for products by name\n@app.route('/search_products', methods=['GET'])\ndef search_products():\n    query = request.args.get('query', '').lower()",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "search_page",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def search_page():\n    return render_template('index.html')\n# Route to search for products by name\n@app.route('/search_products', methods=['GET'])\ndef search_products():\n    query = request.args.get('query', '').lower()\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    product_list = [{'product_name': product['product_name'], 'product_link': product['product_link']} for product in filtered_products]\n    return jsonify(product_list)\n# Route to show product details in a separate page",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "search_products",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def search_products():\n    query = request.args.get('query', '').lower()\n    filtered_products = [product for product in product_data if query in product['product_name'].lower()]\n    product_list = [{'product_name': product['product_name'], 'product_link': product['product_link']} for product in filtered_products]\n    return jsonify(product_list)\n# Route to show product details in a separate page\n@app.route('/product/<path:product_url>')\ndef product_details(product_url):\n    product_url = product_url.strip().lower().rstrip('/')\n    product = next((product for product in product_data if product['product_link'].strip().lower().rstrip('/') == product_url), None)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "product_details",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def product_details(product_url):\n    product_url = product_url.strip().lower().rstrip('/')\n    product = next((product for product in product_data if product['product_link'].strip().lower().rstrip('/') == product_url), None)\n    if product is None:\n        return render_template('404.html'), 404\n    plot_url = create_review_graphs(product['reviews'])\n    plot_url2 = create_sentiment_graph(product['reviews'])\n    plot_url3 = create_review_trend_graph(product['reviews'])\n    plot_url4 = create_keyword_graph(product['reviews'])\n    return render_template('product_details.html', product=product, plot_url=plot_url, plot_url2=plot_url2, plot_url3=plot_url3, plot_url4=plot_url4)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app = Flask(__name__)\n# Load the JSON data (merged_product_reviews.json)\njson_file_path = 'merged_product_reviews.json'\nif os.path.exists(json_file_path):\n    with open(json_file_path, 'r', encoding='utf-8') as f:\n        product_data = json.load(f)\nelse:\n    raise FileNotFoundError(f\"{json_file_path} not found. Ensure the file exists.\")\n# Helper function to generate the review distribution graph\ndef create_review_graphs(product_reviews):",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "json_file_path",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "json_file_path = 'merged_product_reviews.json'\nif os.path.exists(json_file_path):\n    with open(json_file_path, 'r', encoding='utf-8') as f:\n        product_data = json.load(f)\nelse:\n    raise FileNotFoundError(f\"{json_file_path} not found. Ensure the file exists.\")\n# Helper function to generate the review distribution graph\ndef create_review_graphs(product_reviews):\n    df = pd.DataFrame(product_reviews)\n    df['review_collected_date'] = pd.to_datetime(df['review_collected_date'], errors='coerce')",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "py_file_path",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "py_file_path = 'url_dump_2024_09_23_17_12_10.py'\n# Read the Python file contents\nwith open(py_file_path, 'r', encoding='utf-8') as f:\n    py_content = f.read()\n# Extract the product data from the Python file\nproduct_data_str = py_content.split(\"CATEGORIES = \")[1]\nproduct_data = ast.literal_eval(product_data_str)  # Safely evaluate the Python list\n# Convert product data to a DataFrame\nproduct_df = pd.DataFrame(product_data, columns=['url', 'name', 'rating_star', 'rating_nb_reviews', 'price'])\n# Step 2: Load review data from the CSV file (output_with_sentiments_keywords.csv)",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "product_data_str",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "product_data_str = py_content.split(\"CATEGORIES = \")[1]\nproduct_data = ast.literal_eval(product_data_str)  # Safely evaluate the Python list\n# Convert product data to a DataFrame\nproduct_df = pd.DataFrame(product_data, columns=['url', 'name', 'rating_star', 'rating_nb_reviews', 'price'])\n# Step 2: Load review data from the CSV file (output_with_sentiments_keywords.csv)\ncsv_file_path = 'output_with_sentiments_keywords.csv'\nreview_df = pd.read_csv(csv_file_path, sep=';')\n# Step 3: Normalize URLs in both DataFrames (lowercase and remove trailing slashes, ensure https)\nproduct_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "product_data",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "product_data = ast.literal_eval(product_data_str)  # Safely evaluate the Python list\n# Convert product data to a DataFrame\nproduct_df = pd.DataFrame(product_data, columns=['url', 'name', 'rating_star', 'rating_nb_reviews', 'price'])\n# Step 2: Load review data from the CSV file (output_with_sentiments_keywords.csv)\ncsv_file_path = 'output_with_sentiments_keywords.csv'\nreview_df = pd.read_csv(csv_file_path, sep=';')\n# Step 3: Normalize URLs in both DataFrames (lowercase and remove trailing slashes, ensure https)\nproduct_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "product_df",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "product_df = pd.DataFrame(product_data, columns=['url', 'name', 'rating_star', 'rating_nb_reviews', 'price'])\n# Step 2: Load review data from the CSV file (output_with_sentiments_keywords.csv)\ncsv_file_path = 'output_with_sentiments_keywords.csv'\nreview_df = pd.read_csv(csv_file_path, sep=';')\n# Step 3: Normalize URLs in both DataFrames (lowercase and remove trailing slashes, ensure https)\nproduct_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews\nreviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "csv_file_path",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "csv_file_path = 'output_with_sentiments_keywords.csv'\nreview_df = pd.read_csv(csv_file_path, sep=';')\n# Step 3: Normalize URLs in both DataFrames (lowercase and remove trailing slashes, ensure https)\nproduct_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews\nreviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL\nfor index, row in review_df.iterrows():\n    url = row['review_url_src']",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "review_df",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "review_df = pd.read_csv(csv_file_path, sep=';')\n# Step 3: Normalize URLs in both DataFrames (lowercase and remove trailing slashes, ensure https)\nproduct_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews\nreviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL\nfor index, row in review_df.iterrows():\n    url = row['review_url_src']\n    # If the URL is not in the dictionary, initialize an empty list",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "product_df['url']",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "product_df['url'] = product_df['url'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\nreview_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews\nreviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL\nfor index, row in review_df.iterrows():\n    url = row['review_url_src']\n    # If the URL is not in the dictionary, initialize an empty list\n    if url not in reviews_dict:\n        reviews_dict[url] = []",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "review_df['review_url_src']",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "review_df['review_url_src'] = review_df['review_url_src'].str.lower().str.rstrip('/').str.replace('http://', 'https://')\n# Step 4: Create a dictionary for the CSV file reviews\nreviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL\nfor index, row in review_df.iterrows():\n    url = row['review_url_src']\n    # If the URL is not in the dictionary, initialize an empty list\n    if url not in reviews_dict:\n        reviews_dict[url] = []\n    # Append the review data as a dictionary of values to the dictionary",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "reviews_dict",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "reviews_dict = {}\n# Iterate through the review DataFrame and add each review to the corresponding URL\nfor index, row in review_df.iterrows():\n    url = row['review_url_src']\n    # If the URL is not in the dictionary, initialize an empty list\n    if url not in reviews_dict:\n        reviews_dict[url] = []\n    # Append the review data as a dictionary of values to the dictionary\n    reviews_dict[url].append({\n        \"review_stars\": row['review_stars'],",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "merged_output",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "merged_output = []\nfor index, product_row in product_df.iterrows():\n    product_url = product_row['url']\n    product_name = product_row['name']\n    # Find matching reviews for this product URL from the reviews_dict\n    product_reviews = reviews_dict.get(product_url, [])\n    # Merge the product information with the reviews for that product\n    merged_output.append({\n        'product_name': product_name,\n        'price': product_row['price'],",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "output_file_path",
        "kind": 5,
        "importPath": "backend.merging_py_and_csv_in_json",
        "description": "backend.merging_py_and_csv_in_json",
        "peekOfCode": "output_file_path = 'merged_product_reviews.json'\nwith open(output_file_path, 'w', encoding='utf-8') as f:\n    json.dump(merged_output, f, ensure_ascii=False, indent=4)\nprint(f\"Merged product and review data saved to {output_file_path}\")\n# import pandas as pd\n# import ast\n# # Step 1: Load and parse the Python file as a string (reading it like a CSV)\n# py_file_path = 'url_dump_2024_09_23_17_12_10.py'  # Replace with actual file path\n# # Read the contents of the Python file\n# with open(py_file_path, 'r', encoding='utf-8') as f:",
        "detail": "backend.merging_py_and_csv_in_json",
        "documentation": {}
    },
    {
        "label": "CATEGORIES",
        "kind": 5,
        "importPath": "backend.url_dump_2024_09_23_17_12_10",
        "description": "backend.url_dump_2024_09_23_17_12_10",
        "peekOfCode": "CATEGORIES = [ \n['https://www.dermstore.com/obagi-medical-c-fx-c-clarifying-serum/11288929.html', 'Obagi Medical Obagi-C Fx System C-Clarifying Serum (1 oz.)', '4.5', '40', '$135.00'],\n['https://www.dermstore.com/obagi-medical-hydrate-facial-moisturizer/11291537.html', 'Obagi Medical Hydrate Facial Moisturizer (1.7 oz.)', '4.8', '362', '$58.00'],\n['https://www.dermstore.com/obagi-medical-nu-derm-clear-fx/11288915.html', 'Obagi Medical Nu-Derm Clear Fx (2 oz.)', '4.6', '149', '$113.00'],\n['https://www.dermstore.com/skinceuticals-c-e-ferulic-with-15-l-ascorbic-acid-vitamin-c-serum-30ml/11289609.html', 'SkinCeuticals C E Ferulic', '4.7', '5362', '$182.00'],\n['https://www.dermstore.com/skinmedica-tns-advanced-serum-28.4g/12596429.html', 'SkinMedica TNS Advanced+ Serum', '4.3', '473', '$295.00'],\n['https://www.dermstore.com/eltamd-uv-clear-spf46-broad-spectrum-duo/12538013.html', 'EltaMD Exclusive UV Clear SPF 46 Broad-Spectrum Duo', '4.8', '5131', '$73.00'],\n['https://www.dermstore.com/skinceuticals-triple-lipid-restore-2-4-2/11290635.html', 'SkinCeuticals Triple Lipid Restore 242', '4.8', '2061', '$155.00'],\n['https://www.dermstore.com/skinmedica-ha5-hydra-collagen-replenish-and-restore-hydrator-60ml/15449378.html', 'SkinMedica HA5 Hydra Collagen Replenish and Restore Hydrator 60ml', '3.0', '1', '$192.00'],\n['https://www.dermstore.com/neocutis-lumiere-firm-riche-extra-moisturizing-illuminating-and-tightening-eye-cream-15ml/12664555.html', 'Neocutis LUMI√àRE FIRM RICHE Extra Moisturizing Illuminating & Tightening Eye Cream', '4.7', '156', '$125.00'],",
        "detail": "backend.url_dump_2024_09_23_17_12_10",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "process_datas",
        "description": "process_datas",
        "peekOfCode": "def main():\n    # Load the model\n    model = load_model('model/sentiment_analysis_model.h5')\n    new_data = pd.read_csv(\"./exchange/input/input.csv\", sep=\";\")\n    # Train the tokenizer\n    tokenizer = Tokenizer(num_words=5000, split=\" \")\n    tokenizer.fit_on_texts(new_data['review_thoughts'].values)\n    # Tokenizer\n    #tokenizer = Tokenizer(num_words=5000, split=\" \")\n    # Define the predict function",
        "detail": "process_datas",
        "documentation": {}
    },
    {
        "label": "REVIEWS",
        "kind": 5,
        "importPath": "review_dump_2024_09_24_08_39_53",
        "description": "review_dump_2024_09_24_08_39_53",
        "peekOfCode": "REVIEWS = [ \n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '2', 'Disappointed', \"First off the quality of the topper is awful and I lost product even though it was securely screwed tight. I didn't perceive any improvements, \\xa0happier with CE ferulic\", 'Mil', '2024-08-16T17:07:32.695Z', 'False', '3', '0', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '1', 'Dropper leaks everything out.', \"This product cannot be taken anywhere. I have purchased three‚Ä¶ THREE‚Ä¶‚Ä¶ And it leaks everywhere no matter how tight you make it. It's too expensive to even lose a drop and I think I've gotten nine drops out of three bottles. We go back-and-forth to our lake house. I even keep it in my purse stand up right and my Holland's died. My purse is wet and the bottle still stand up at the top up right this is ridiculous. It's too expensive for you not to be concerned about the Dropper bottle itself. It sucks. If I could write this product -100 I would\", 'Frannie', '2024-07-08T18:26:21.118Z', 'False', '6', '1', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '5', 'VITAMIN C', \"The only way I get my vitamin C. Love that it's a liquid-like consistency that absorbs right into the skin.\", 'SP', '2024-07-07T22:23:31.341Z', 'False', '1', '0', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '5', 'good for sensitive skin', 'use as a vit c serum, have sensitive skin and this has worked very well', 'YM', '2024-03-11T01:50:28.792Z', 'False', '5', '0', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '1', 'Caused perioral dermatitis', \"I'd had issues with other vitamin C serums causing perioral dermatitis in the past, but the medical aesthetician convinced me that this one was 'different' and would 'heal' my skin. It wasn't, and within in a week of using it the stubborn dermatitis that had taken me months to get rid of came back. I should have trusted my gut and will do so next time.\", 'AMH', '2024-02-09T04:35:07.644Z', 'False', '19', '1', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '1', 'Caused a breakout', \"This serum was recommended by the facialist at my dermatologist's office, but it caused a bad breakout/reaction on my forehead. I patch tested behind my ear without a problem, but after a few days using it on my face, I had a horrible breakout. Disappointed. Maybe I'll try to use it on my arms, but my face didn't like it!\", 'Lablue', '2024-01-26T18:27:13.163Z', 'False', '7', '0', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '5', 'Great product but I would not buy from this company', \"I really love this product and does help me with stubborn breakouts. Here's where the problem is. This company used a courier to deliver the product, and the product never arrived. I went through 3 weeks of back n forth trying to get them to replace or refund. I sent photos of the delivery person at the wrong place, filled out lost item paper work etc. They kept saying they need to investigate. Never received the item. Had to blow a gasket to get a refund. For that, I am done with dermstore and I've used them for years\", 'customer service is imporrtant', '2024-01-12T20:50:25.763Z', 'False', '46', '2', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '5', 'Completely changed my skin!', 'I use this serum in conjunction with their active peel pad system. My skin has never looked smoother and, brighter. My hyperpigmentation has decreased since using this product and it leaves me with a beautiful dewy glow.', 'Niecie', '2023-09-13T00:00:00.000Z', 'False', '11', '0', '2024-09-24'),\n('https://www.dermstore.com/is-clinical-pro-heal-serum-advance-plus/11291965.html', '5', 'Love it', 'My skin loves this stuff! Will forever be my skins are staple!', 'Amanda', '2023-08-20T00:00:00.000Z', 'True', '3', '0', '2024-09-24'),",
        "detail": "review_dump_2024_09_24_08_39_53",
        "documentation": {}
    }
]